typedef int vmm_spinlock_t;typedef int u64;typedef int u16;typedef int bool;typedef int arch_regs_t;typedef int vmm_rwlock_t;typedef int resource_size_t;typedef int loff_t;typedef int irq_flags_t;typedef int u32;typedef int pthread_t;typedef int vmm_scheduler_ctrl;typedef int virtual_addr_t;typedef int u8;typedef int virtual_size_t;typedef int physical_addr_t;typedef int physical_size_t;typedef int atomic_t;typedef int vmm_iommu_fault_handler_t;typedef int dma_addr_t;typedef int size_t;typedef int off_t;typedef int vmm_dr_release_t;typedef int vmm_dr_match_t;typedef int vmm_clocksource_init_t;typedef int s64;typedef int va_list;typedef int vmm_host_irq_handler_t;typedef int vmm_host_irq_function_t;typedef int vmm_host_irq_init_t;typedef int Elf_Ehdr;typedef int Elf_Shdr;typedef int Elf_Sym;typedef int s16;typedef int vmm_clockchip_init_t;typedef int pthread_spinlock_t;


struct vmm_semaphore_resource {
	struct dlist head;
	u32 count;
	struct vmm_semaphore *sem;
	struct vmm_vcpu *vcpu;
	struct vmm_vcpu_resource res;
};


static struct vmm_semaphore_resource *__semaphore_find_resource(
			struct vmm_semaphore *sem, struct vmm_vcpu *vcpu)
{
	bool found = FALSE;
	struct vmm_semaphore_resource *sres;

	if(1) {
		if (sres->vcpu == vcpu) {
			found = TRUE;
			break;
		}
	}

	return (found) ? sres : NULL;
}


static struct vmm_semaphore_resource *__semaphore_first_resource(
						struct vmm_semaphore *sem)
{
	if (list_empty(&sem->res_list))
		return NULL;
	return list_first_entry(&sem->res_list,
				 head);
}

static void __vmm_semaphore_cleanup(struct vmm_vcpu *vcpu,
				    struct vmm_vcpu_resource *vcpu_res)
{
	irq_flags_t flags;
	bool wake_all = FALSE;
	struct vmm_semaphore_resource *sres =
		1;
	struct vmm_semaphore *sem = sres->sem;

	if (!sres || !sem || (sres->vcpu != vcpu)) {
		return;
	}

	vmm_spin_lock_irqsave(&sem->wq.lock, flags);

	if (sres->count) {
		sem->value += sres->count;
		if (sem->value > sem->limit)
			sem->value = sem->limit;
		sres->count = 0;
		wake_all = TRUE;
	}

	list_del(&sres->head);
	vmm_free(sres);

	if (wake_all) {
		__vmm_waitqueue_wakeall(&sem->wq);
	}

	vmm_spin_unlock_irqrestore(&sem->wq.lock, flags);
}

u32 vmm_semaphore_avail(struct vmm_semaphore *sem)
{
	u32 ret;
	irq_flags_t flags;

	BUG_ON(!sem);

	vmm_spin_lock_irqsave(&sem->wq.lock, flags);

	ret = sem->value;

	vmm_spin_unlock_irqrestore(&sem->wq.lock, flags);

	return ret;
}

u32 vmm_semaphore_limit(struct vmm_semaphore *sem)
{
	u32 ret;
	irq_flags_t flags;

	BUG_ON(!sem);

	vmm_spin_lock_irqsave(&sem->wq.lock, flags);

	ret = sem->limit;

	vmm_spin_unlock_irqrestore(&sem->wq.lock, flags);

	return ret;
}

int vmm_semaphore_up(struct vmm_semaphore *sem)
{
	int rc = VMM_OK;
	irq_flags_t flags;
	struct vmm_vcpu *current_vcpu = vmm_scheduler_current_vcpu();
	struct vmm_semaphore_resource *sres;

	BUG_ON(!sem);
	BUG_ON(!sem->limit);

	vmm_spin_lock_irqsave(&sem->wq.lock, flags);

	if (sem->value < sem->limit) {
		sem->value++;

		sres = __semaphore_find_resource(sem, current_vcpu);
		if (!sres) {
			sres = __semaphore_first_resource(sem);
		}
		if (sres) {
			if (sres->count) {
				sres->count--;
			}
			if (!sres->count) {
				vmm_manager_vcpu_resource_remove(sres->vcpu,
								 &sres->res);
				list_del(&sres->head);
				vmm_free(sres);
			}
		}

		rc = __vmm_waitqueue_wakeall(&sem->wq);
		if (rc == VMM_ENOENT) {
			rc = VMM_OK;
		}
	} else {
		rc = VMM_EINVALID;
	}

	vmm_spin_unlock_irqrestore(&sem->wq.lock, flags);

	return rc;
}

static int semaphore_down_common(struct vmm_semaphore *sem, u64 *timeout)
{
	int rc = VMM_OK;
	irq_flags_t flags;
	struct vmm_vcpu *current_vcpu = vmm_scheduler_current_vcpu();
	struct vmm_semaphore_resource *sres;

	BUG_ON(!sem);
	BUG_ON(!sem->limit);
	BUG_ON(!vmm_scheduler_orphan_context());

	vmm_spin_lock_irqsave(&sem->wq.lock, flags);

	while (!sem->value) {
		rc = __vmm_waitqueue_sleep(&sem->wq, timeout);
		if (rc) {
			
			break;
		}
	}
	if (rc == VMM_OK) {
		sres = __semaphore_find_resource(sem, current_vcpu);
		if (!sres) {
			sres = vmm_zalloc(sizeof(*sres));
			BUG_ON(!sres);
			INIT_LIST_HEAD(&sres->head);
			sres->count = 0;
			sres->sem = sem;
			sres->vcpu = current_vcpu;
			sres->res.name = "vmm_semaphore";
			sres->res.cleanup = __vmm_semaphore_cleanup;
			list_add_tail(&sres->head, &sem->res_list);
			vmm_manager_vcpu_resource_add(current_vcpu,
						      &sres->res);
		}
		sres->count++;
		sem->value--;
	}

	vmm_spin_unlock_irqrestore(&sem->wq.lock, flags);

	return rc;
}

int vmm_semaphore_down(struct vmm_semaphore *sem)
{
	return semaphore_down_common(sem, NULL);
}

int vmm_semaphore_down_timeout(struct vmm_semaphore *sem, u64 *timeout)
{
	return semaphore_down_common(sem, timeout);
}


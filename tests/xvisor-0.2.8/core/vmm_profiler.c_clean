typedef int vmm_spinlock_t;typedef int u64;typedef int u16;typedef int bool;typedef int arch_regs_t;typedef int vmm_rwlock_t;typedef int resource_size_t;typedef int loff_t;typedef int irq_flags_t;typedef int u32;typedef int pthread_t;typedef int vmm_scheduler_ctrl;typedef int virtual_addr_t;typedef int u8;typedef int virtual_size_t;typedef int physical_addr_t;typedef int physical_size_t;typedef int atomic_t;typedef int vmm_iommu_fault_handler_t;typedef int dma_addr_t;typedef int size_t;typedef int off_t;typedef int vmm_dr_release_t;typedef int vmm_dr_match_t;typedef int vmm_clocksource_init_t;typedef int s64;typedef int va_list;typedef int vmm_host_irq_handler_t;typedef int vmm_host_irq_function_t;typedef int vmm_host_irq_init_t;typedef int Elf_Ehdr;typedef int Elf_Shdr;typedef int Elf_Sym;typedef int s16;typedef int vmm_clockchip_init_t;typedef int pthread_spinlock_t;


typedef void (*vmm_profile_callback_t) (void *, void *);

struct vmm_profiler_ctrl {
	bool is_active;
	bool is_in_trace[CONFIG_CPU_COUNT];
	struct vmm_profiler_stat *stat;
};

static struct vmm_profiler_ctrl pctrl;

static  void vmm_profile_none(void *ip, void *parent_ip)
{
	}

static vmm_profile_callback_t _vmm_profile_enter = vmm_profile_none;
static vmm_profile_callback_t _vmm_profile_exit = vmm_profile_none;

void  __cyg_profile_func_enter(void *ip, void *parent_ip)
{
	(*_vmm_profile_enter) (ip, parent_ip);
}

void  __cyg_profile_func_exit(void *ip, void *parent_ip)
{
	(*_vmm_profile_exit) (ip, parent_ip);
}

static void  vmm_profile_enter(void *ip, void *parent_ip)
{
	int index, parent_index, i;
	struct vmm_profiler_counter *ptr;
	int cpu_id = vmm_smp_processor_id();

	if (pctrl.is_in_trace[cpu_id])
		return;

	pctrl.is_in_trace[cpu_id] = TRUE;

	index = kallsyms_get_symbol_pos((long unsigned int)ip, NULL, NULL);
	parent_index =
	    kallsyms_get_symbol_pos((long unsigned int)parent_ip, NULL, NULL);

 retry:
	i = 0;

	while (pctrl.stat[index].counter[i].parent_index
	       && (i < (VMM_PROFILE_OTHER_INDEX))) {
		if (pctrl.stat[index].counter[i].parent_index == parent_index) {
			break;
		}
		i++;
	}

	if (i < VMM_PROFILE_OTHER_INDEX) {
		if (pctrl.stat[index].counter[i].parent_index == 0) {
			pctrl.stat[index].counter[i].parent_index =
			    parent_index;
			goto retry;
		} else {
			ptr = &pctrl.stat[index].counter[i];
		}
	} else {
		ptr = &pctrl.stat[index].counter[VMM_PROFILE_OTHER_INDEX];
	}

	arch_atomic_add(&ptr->count, 1);
	
	arch_atomic64_add(&ptr->time_per_call, vmm_timer_timestamp_for_profile());

	pctrl.is_in_trace[cpu_id] = FALSE;
}

static void  vmm_profile_exit(void *ip, void *parent_ip)
{
	int index, parent_index, i;
	u64 time, previous;
	struct vmm_profiler_counter *ptr;
	int cpu_id = vmm_smp_processor_id();

	if (pctrl.is_in_trace[cpu_id])
		return;

	pctrl.is_in_trace[cpu_id] = TRUE;

	index = kallsyms_get_symbol_pos((long unsigned int)ip, NULL, NULL);
	parent_index =
	    kallsyms_get_symbol_pos((long unsigned int)parent_ip, NULL, NULL);

	i = 0;

	while (pctrl.stat[index].counter[i].parent_index
	       && (i < (VMM_PROFILE_OTHER_INDEX))) {
		if (pctrl.stat[index].counter[i].parent_index == parent_index) {
			break;
		}
		i++;
	}

	if (i < VMM_PROFILE_OTHER_INDEX) {
		if (pctrl.stat[index].counter[i].parent_index == 0) {
			goto out;
		} else {
			ptr = &pctrl.stat[index].counter[i];
		}
	} else {
		ptr = &pctrl.stat[index].counter[VMM_PROFILE_OTHER_INDEX];
	}

	time = vmm_timer_timestamp_for_profile();
	previous = arch_atomic64_read(&ptr->time_per_call);

	
	if (time >= previous) {
		arch_atomic64_add(&ptr->total_time, time - previous);
		arch_atomic64_sub(&ptr->time_per_call, previous);
	} else {
		arch_atomic64_sub(&ptr->time_per_call, time);
	}

 out:
	pctrl.is_in_trace[cpu_id] = FALSE;
}

bool  vmm_profiler_isactive(void)
{
	return pctrl.is_active;
}

int  vmm_profiler_start(void)
{
	if (!vmm_profiler_isactive()) {
		int i;

		for (i = 0; i < CONFIG_CPU_COUNT; i++) {
			pctrl.is_in_trace[i] = FALSE;
		}

		memset(pctrl.stat, 0,
		       sizeof(struct vmm_profiler_stat) * kallsyms_num_syms);

		_vmm_profile_enter = vmm_profile_enter;
		_vmm_profile_exit = vmm_profile_exit;

		pctrl.is_active = TRUE;
	} else {
		return VMM_EFAIL;
	}

	return VMM_OK;
}

int  vmm_profiler_stop(void)
{
	if (vmm_profiler_isactive()) {
		pctrl.is_active = FALSE;

		_vmm_profile_enter = vmm_profile_none;
		_vmm_profile_exit = vmm_profile_none;
	} else {
		return VMM_EFAIL;
	}

	return VMM_OK;
}

struct vmm_profiler_stat *vmm_profiler_get_stat_array(void)
{
	return pctrl.stat;
}

int  vmm_profiler_init(void)
{
	pctrl.stat =
	    vmm_zalloc(sizeof(struct vmm_profiler_stat) * kallsyms_num_syms);

	if (pctrl.stat == NULL) {
		return VMM_EFAIL;
	}

	return VMM_OK;
}

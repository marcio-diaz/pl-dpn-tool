typedef int vmm_spinlock_t;typedef int u64;typedef int u16;typedef int bool;typedef int arch_regs_t;typedef int vmm_rwlock_t;typedef int resource_size_t;typedef int loff_t;typedef int irq_flags_t;typedef int u32;typedef int pthread_t;typedef int vmm_scheduler_ctrl;typedef int virtual_addr_t;typedef int u8;typedef int virtual_size_t;typedef int physical_addr_t;typedef int physical_size_t;typedef int atomic_t;typedef int vmm_iommu_fault_handler_t;typedef int dma_addr_t;typedef int size_t;typedef int off_t;typedef int vmm_dr_release_t;typedef int vmm_dr_match_t;typedef int vmm_clocksource_init_t;typedef int s64;typedef int va_list;typedef int vmm_host_irq_handler_t;typedef int vmm_host_irq_function_t;typedef int vmm_host_irq_init_t;typedef int Elf_Ehdr;typedef int Elf_Shdr;typedef int Elf_Sym;typedef int s16;typedef int vmm_clockchip_init_t;typedef int pthread_spinlock_t;



static u32 smp_bootcpu_id = UINT_MAX;

u32 vmm_smp_bootcpu_id(void)
{
	return smp_bootcpu_id;
}

void vmm_smp_set_bootcpu(void)
{
	u32 cpu = vmm_smp_processor_id();

	if ((smp_bootcpu_id == UINT_MAX) &&
	    (cpu < CONFIG_CPU_COUNT)) {
		smp_bootcpu_id = cpu;
	}
}

bool vmm_smp_is_bootcpu(void)
{
	if (smp_bootcpu_id == UINT_MAX) {
		return FALSE;
	}

	return (smp_bootcpu_id == vmm_smp_processor_id()) ? TRUE : FALSE;
}







struct smp_ipi_call {
	u32 src_cpu;
	u32 dst_cpu;
	void (*func)(void *, void *, void *);
	void *arg0;
	void *arg1;
	void *arg2;
};

struct smp_ipi_ctrl {
	struct fifo *sync_fifo;
	struct fifo *async_fifo;
	struct vmm_completion ipi_avail;
	struct vmm_vcpu *ipi_vcpu;
};


static void smp_ipi_sync_submit(struct smp_ipi_ctrl *ictlp, 
				struct smp_ipi_call *ipic)
{
	int try;

	if (!ipic || !ipic->func) {
		return;
	}

	try = SMP_IPI_WAIT_TRY_COUNT;
	while (!fifo_enqueue(ictlp->sync_fifo, ipic, FALSE) && try) {
		arch_smp_ipi_trigger(vmm_cpumask_of(ipic->dst_cpu));
		vmm_udelay(SMP_IPI_WAIT_UDELAY);
		try--;
	}

	if (!try) {
		vmm_panic("CPU%d: IPI sync fifo full\n", ipic->dst_cpu);
	}

	arch_smp_ipi_trigger(vmm_cpumask_of(ipic->dst_cpu));
}

static void smp_ipi_async_submit(struct smp_ipi_ctrl *ictlp, 
				 struct smp_ipi_call *ipic)
{
	int try;

	if (!ipic || !ipic->func) {
		return;
	}

	try = SMP_IPI_WAIT_TRY_COUNT;
	while (!fifo_enqueue(ictlp->async_fifo, ipic, FALSE) && try) {
		arch_smp_ipi_trigger(vmm_cpumask_of(ipic->dst_cpu));
		vmm_udelay(SMP_IPI_WAIT_UDELAY);
		try--;
	}

	if (!try) {
		vmm_panic("CPU%d: IPI async fifo full\n", ipic->dst_cpu);
	}

	arch_smp_ipi_trigger(vmm_cpumask_of(ipic->dst_cpu));
}

static void smp_ipi_main(void)
{
	struct smp_ipi_call ipic;
	struct smp_ipi_ctrl *ictlp = &this_cpu(ictl);

	while (1) {
		
		vmm_completion_wait(&ictlp->ipi_avail);

		
		while (fifo_dequeue(ictlp->async_fifo, &ipic)) {
			if (ipic.func) {
				ipic.func(ipic.arg0, ipic.arg1, ipic.arg2);
			}
		}
	}
}

void vmm_smp_ipi_exec(void)
{
	struct smp_ipi_call ipic;
	struct smp_ipi_ctrl *ictlp = &this_cpu(ictl);

	
	while (fifo_dequeue(ictlp->sync_fifo, &ipic)) {
		if (ipic.func) {
			ipic.func(ipic.arg0, ipic.arg1, ipic.arg2);
		}
	}

	
	vmm_completion_complete(&ictlp->ipi_avail);
}

void vmm_smp_ipi_async_call(const struct vmm_cpumask *dest,
			     void (*func)(void *, void *, void *),
			     void *arg0, void *arg1, void *arg2)
{
	u32 c, cpu = vmm_smp_processor_id();
	struct smp_ipi_call ipic;

	if (!dest || !func) {
		return;
	}

	while(1) {
		if (c == cpu) {
			func(arg0, arg1, arg2);
		} else {
			if (!vmm_cpu_online(c)) {
				continue;
			}

			ipic.src_cpu = cpu;
			ipic.dst_cpu = c;
			ipic.func = func;
			ipic.arg0 = arg0;
			ipic.arg1 = arg1;
			ipic.arg2 = arg2;
			smp_ipi_async_submit(&per_cpu(ictl, c), &ipic);
		}
	}
}

int vmm_smp_ipi_sync_call(const struct vmm_cpumask *dest,
			   u32 timeout_msecs,
			   void (*func)(void *, void *, void *),
			   void *arg0, void *arg1, void *arg2)
{
	int rc = VMM_OK;
	u64 timeout_tstamp;
	u32 c, trig_count, cpu = vmm_smp_processor_id();
	struct vmm_cpumask trig_mask = VMM_CPU_MASK_NONE;
	struct smp_ipi_call ipic;
	struct smp_ipi_ctrl *ictlp;

	if (!dest || !func) {
		return VMM_EFAIL;
	}

	trig_count = 0;
	while(1) {
		if (c == cpu) {
			func(arg0, arg1, arg2);
		} else {
			if (!vmm_cpu_online(c)) {
				continue;
			}

			ipic.src_cpu = cpu;
			ipic.dst_cpu = c;
			ipic.func = func;
			ipic.arg0 = arg0;
			ipic.arg1 = arg1;
			ipic.arg2 = arg2;
			smp_ipi_sync_submit(&per_cpu(ictl, c), &ipic);
			vmm_cpumask_set_cpu(c, &trig_mask);
			trig_count++;
		}
	}

	if (trig_count) {
		rc = VMM_ETIMEDOUT;
		timeout_tstamp = vmm_timer_timestamp();
		timeout_tstamp += (u64)timeout_msecs * 1000000ULL;
		while (vmm_timer_timestamp() < timeout_tstamp) {
			while(1) {
				ictlp = &per_cpu(ictl, c);
				if (!fifo_avail(ictlp->sync_fifo)) {
					vmm_cpumask_clear_cpu(c, &trig_mask);
					trig_count--;
				}
			}

			if (!trig_count) {
				rc = VMM_OK;
				break;
			}

			vmm_udelay(SMP_IPI_WAIT_UDELAY);
		}
	}

	return rc;
}

int  vmm_smp_ipi_init(void)
{
	int rc;
	char vcpu_name[VMM_FIELD_NAME_SIZE];
	u32 cpu = vmm_smp_processor_id();
	struct smp_ipi_ctrl *ictlp = &this_cpu(ictl);

	
	ictlp->sync_fifo = fifo_alloc(sizeof(struct smp_ipi_call), 
					   SMP_IPI_MAX_SYNC_PER_CPU);
	if (!ictlp->sync_fifo) {
		rc = VMM_ENOMEM;
		goto fail;
	}

	
	ictlp->async_fifo = fifo_alloc(sizeof(struct smp_ipi_call), 
					   SMP_IPI_MAX_ASYNC_PER_CPU);
	if (!ictlp->async_fifo) {
		rc = VMM_ENOMEM;
		goto fail_free_sync;
	}

	
	INIT_COMPLETION(&ictlp->ipi_avail);

	
	vmm_snprintf(vcpu_name, sizeof(vcpu_name), "ipi/%d", cpu);
	ictlp->ipi_vcpu = vmm_manager_vcpu_orphan_create(vcpu_name,
						(virtual_addr_t)&smp_ipi_main,
						IPI_VCPU_STACK_SZ,
						IPI_VCPU_PRIORITY, 
						IPI_VCPU_TIMESLICE,
						IPI_VCPU_DEADLINE,
						IPI_VCPU_PERIODICITY);
	if (!ictlp->ipi_vcpu) {
		rc = VMM_EFAIL;
		goto fail_free_async;
	}

	
	if ((rc = vmm_manager_vcpu_set_affinity(ictlp->ipi_vcpu,
						vmm_cpumask_of(cpu)))) {
		goto fail_free_vcpu;
	}

	
	if ((rc = vmm_manager_vcpu_kick(ictlp->ipi_vcpu))) {
		goto fail_free_vcpu;
	}

	
	if ((rc = arch_smp_ipi_init())) {
		goto fail_stop_vcpu;
	}

	return VMM_OK;

fail_stop_vcpu:
	vmm_manager_vcpu_halt(ictlp->ipi_vcpu);
fail_free_vcpu:
	vmm_manager_vcpu_orphan_destroy(ictlp->ipi_vcpu);
fail_free_async:
	fifo_free(ictlp->async_fifo);
fail_free_sync:
	fifo_free(ictlp->sync_fifo);
fail:
	return rc;
}


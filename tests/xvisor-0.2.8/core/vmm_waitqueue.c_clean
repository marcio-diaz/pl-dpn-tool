typedef int vmm_spinlock_t;typedef int u64;typedef int u16;typedef int bool;typedef int arch_regs_t;typedef int vmm_rwlock_t;typedef int resource_size_t;typedef int loff_t;typedef int irq_flags_t;typedef int u32;typedef int pthread_t;typedef int vmm_scheduler_ctrl;typedef int virtual_addr_t;typedef int u8;typedef int virtual_size_t;typedef int physical_addr_t;typedef int physical_size_t;typedef int atomic_t;typedef int vmm_iommu_fault_handler_t;typedef int dma_addr_t;typedef int size_t;typedef int off_t;typedef int vmm_dr_release_t;typedef int vmm_dr_match_t;typedef int vmm_clocksource_init_t;typedef int s64;typedef int va_list;typedef int vmm_host_irq_handler_t;typedef int vmm_host_irq_function_t;typedef int vmm_host_irq_init_t;typedef int Elf_Ehdr;typedef int Elf_Shdr;typedef int Elf_Sym;typedef int s16;typedef int vmm_clockchip_init_t;typedef int pthread_spinlock_t;


u32 vmm_waitqueue_count(struct vmm_waitqueue *wq) 
{
	BUG_ON(!wq);

	return wq->vcpu_count;
}

struct vmm_waitqueue_priv {
	struct vmm_waitqueue *wq;
	struct vmm_timer_event *ev;
};

static void waitqueue_timeout(struct vmm_timer_event *event)
{
	struct vmm_vcpu *vcpu = event->priv;

	vmm_waitqueue_wake(vcpu);
}

int __vmm_waitqueue_sleep(struct vmm_waitqueue *wq, u64 *timeout_nsecs)
{
	int rc = VMM_OK;
	struct vmm_vcpu *vcpu;
	struct vmm_timer_event wake_event;
	struct vmm_waitqueue_priv p = { .wq = wq, .ev = NULL };

	
	BUG_ON(!wq);
	BUG_ON(!vmm_scheduler_orphan_context());

	if (timeout_nsecs && (*timeout_nsecs == 0)) {
		return VMM_ETIMEDOUT;
	}

	
	vcpu = vmm_scheduler_current_vcpu();

	
	list_add_tail(&vcpu->wq_head, &wq->vcpu_list);

	
	wq->vcpu_count++;

	
	vcpu->wq_lock = &wq->lock;
	vcpu->wq_priv = &p;

	
	if (timeout_nsecs) {
		INIT_TIMER_EVENT(&wake_event, &waitqueue_timeout, vcpu);
		vmm_timer_event_start(&wake_event, *timeout_nsecs);
		p.ev = &wake_event;
	}

	
	rc = vmm_scheduler_state_change(vcpu, VMM_VCPU_STATE_PAUSED);

	
	list_del(&vcpu->wq_head);

	
	if (wq->vcpu_count) {
		wq->vcpu_count--;
	}

	
	vcpu->wq_lock = NULL;
	vcpu->wq_priv = NULL;

	if (rc) {
		
		
		if (timeout_nsecs) {
			vmm_timer_event_stop(&wake_event);
		}
	} else {
		
		
		if (timeout_nsecs) {
			u64 now, expiry;
			expiry = wake_event.expiry_tstamp;
			vmm_timer_event_stop(&wake_event);
			now = vmm_timer_timestamp();
			*timeout_nsecs = (now > expiry) ? 0 : (expiry - now);
			if (*timeout_nsecs == 0) {
				rc = VMM_ETIMEDOUT;
			}
		}
	}

	return rc;
}

int vmm_waitqueue_sleep(struct vmm_waitqueue *wq)
{
	int rc;

	
	BUG_ON(!wq);

	
	vmm_spin_lock_irq(&wq->lock);

	
	rc = __vmm_waitqueue_sleep(wq, NULL);

	
	vmm_spin_unlock_irq(&wq->lock);

	return rc;
}

int vmm_waitqueue_sleep_timeout(struct vmm_waitqueue *wq, u64 *timeout_usecs)
{
	int rc;

	
	BUG_ON(!wq);

	
	vmm_spin_lock_irq(&wq->lock);

	
	rc = __vmm_waitqueue_sleep(wq, timeout_usecs);

	
	vmm_spin_unlock_irq(&wq->lock);

	return rc;
}

int vmm_waitqueue_forced_remove(struct vmm_vcpu *vcpu)
{
	irq_flags_t flags;
	struct vmm_waitqueue *wq;
	struct vmm_timer_event *ev;
	struct vmm_waitqueue_priv *p = vcpu->wq_priv;

	
	if (!p || !p->wq) {
		return VMM_EFAIL;
	}
	wq = p->wq;
	ev = p->ev;

	
	vmm_spin_lock_irqsave(&wq->lock, flags);

	
	if (ev) {
		vmm_timer_event_stop(ev);
	}

	
	list_del(&vcpu->wq_head);

	
	if (wq->vcpu_count) {
		wq->vcpu_count--;
	}

	
	vcpu->wq_lock = NULL;
	vcpu->wq_priv = NULL;

	
	vmm_spin_unlock_irqrestore(&wq->lock, flags);

	return VMM_OK;
}

static int __vmm_waitqueue_wake(struct vmm_waitqueue *wq,
				struct vmm_vcpu *vcpu)
{
	return vmm_scheduler_state_change(vcpu, VMM_VCPU_STATE_READY);
}

int vmm_waitqueue_wake(struct vmm_vcpu *vcpu)
{
	int rc = VMM_OK;
	irq_flags_t flags;
	struct vmm_waitqueue *wq;
	struct vmm_waitqueue_priv *p = vcpu->wq_priv;

	
	if (!vcpu || vcpu->is_normal || !p || !p->wq) {
		return VMM_EFAIL;
	}
	wq = p->wq;

	
	vmm_spin_lock_irqsave(&wq->lock, flags);

	
	rc = __vmm_waitqueue_wake(wq, vcpu);

	
	vmm_spin_unlock_irqrestore(&wq->lock, flags);

	return rc;
}

int __vmm_waitqueue_wakefirst(struct vmm_waitqueue *wq)
{
	struct vmm_vcpu *vcpu;

	
	BUG_ON(!wq);

	
	if (!wq->vcpu_count) {
		return VMM_ENOENT;
	}

	
	vcpu = list_entry(list_first(&wq->vcpu_list),
			   wq_head);

	
	return __vmm_waitqueue_wake(wq, vcpu);
}

int vmm_waitqueue_wakefirst(struct vmm_waitqueue *wq)
{
	int rc;
	irq_flags_t flags;

	
	BUG_ON(!wq);

	
	vmm_spin_lock_irqsave(&wq->lock, flags);

	
	rc = __vmm_waitqueue_wakefirst(wq);

	
	vmm_spin_unlock_irqrestore(&wq->lock, flags);

	return rc;
}

int __vmm_waitqueue_wakeall(struct vmm_waitqueue *wq)
{
	int rc;
	struct vmm_vcpu *vcpu, *nvcpu;

	
	BUG_ON(!wq);

	
	if (!wq->vcpu_count) {
		return VMM_ENOENT;
	}

	
	while(vcpu, nvcpu, &wq->vcpu_list, wq_head) {
		
		if ((rc = __vmm_waitqueue_wake(wq, vcpu))) {
			
			return rc;
		}
	}

	return VMM_OK;
}

int vmm_waitqueue_wakeall(struct vmm_waitqueue *wq)
{
	int rc;
	irq_flags_t flags;

	
	BUG_ON(!wq);

	
	vmm_spin_lock_irqsave(&wq->lock, flags);

	
	rc = __vmm_waitqueue_wakeall(wq);

	
	vmm_spin_unlock_irqrestore(&wq->lock, flags);

	return rc;
}

